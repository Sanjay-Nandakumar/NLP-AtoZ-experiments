{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_df = pd.read_csv('/Users/dima/Downloads/entity-annotated-corpus (1)/ner_dataset.csv')\n",
    "#ner_df['Word'] = ner_df['Word'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>country</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1           NaN             of   IN      O\n",
       "2           NaN  demonstrators  NNS      O\n",
       "3           NaN           have  VBP      O\n",
       "4           NaN        marched  VBN      O\n",
       "5           NaN        through   IN      O\n",
       "6           NaN         London  NNP  B-geo\n",
       "7           NaN             to   TO      O\n",
       "8           NaN        protest   VB      O\n",
       "9           NaN            the   DT      O\n",
       "10          NaN            war   NN      O\n",
       "11          NaN             in   IN      O\n",
       "12          NaN           Iraq  NNP  B-geo\n",
       "13          NaN            and   CC      O\n",
       "14          NaN         demand   VB      O\n",
       "15          NaN            the   DT      O\n",
       "16          NaN     withdrawal   NN      O\n",
       "17          NaN             of   IN      O\n",
       "18          NaN        British   JJ  B-gpe\n",
       "19          NaN         troops  NNS      O\n",
       "20          NaN           from   IN      O\n",
       "21          NaN           that   DT      O\n",
       "22          NaN        country   NN      O\n",
       "23          NaN              .    .      O\n",
       "24  Sentence: 2       Families  NNS      O\n",
       "25          NaN             of   IN      O\n",
       "26          NaN       soldiers  NNS      O\n",
       "27          NaN         killed  VBN      O\n",
       "28          NaN             in   IN      O\n",
       "29          NaN            the   DT      O"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47958, 47958)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_words = []\n",
    "sentences_tags = []\n",
    "curr_sent_num = -1\n",
    "current_sentence_words = []\n",
    "current_sentence_tags = []\n",
    "for sent_num, word, tag in ner_df[['Sentence #', 'Word', 'Tag']].values:   \n",
    "    if isinstance(sent_num, basestring) and 'Sentence: ' in sent_num:\n",
    "        curr_sent_num = int(sent_num.split(':')[1].strip())\n",
    "        \n",
    "        if current_sentence_words and current_sentence_tags:\n",
    "            sentences_words.append(current_sentence_words)\n",
    "            sentences_tags.append(current_sentence_tags)\n",
    "            \n",
    "        current_sentence_words = []\n",
    "        current_sentence_tags = []\n",
    "        \n",
    "    current_sentence_words.append(word.decode(errors='replace'))\n",
    "    current_sentence_tags.append(tag)\n",
    "\n",
    "len(sentences_words), len(sentences_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not O\n",
      "counting O\n",
      "the O\n",
      "latest O\n",
      "death O\n",
      ", O\n",
      "the O\n",
      "world B-org\n",
      "health I-org\n",
      "organization I-org\n",
      "says O\n",
      "227 O\n",
      "people O\n",
      "around O\n",
      "the O\n",
      "world O\n",
      "have O\n",
      "died O\n",
      "from O\n",
      "bird O\n",
      "flu O\n",
      "since O\n",
      "2003 B-tim\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for w, k in zip(sentences_words[123], sentences_tags[123]): print w, k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 38366 38366\n",
      "Test: 9592 9592\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(sentences_words) * 0.8)\n",
    "\n",
    "train_sentences_words = sentences_words[:train_size]\n",
    "train_sentences_tags = sentences_tags[:train_size]\n",
    "test_sentences_words = sentences_words[train_size:]\n",
    "test_sentences_tags = sentences_tags[train_size:]\n",
    "\n",
    "print 'Train:', len(train_sentences_words), len(train_sentences_tags)\n",
    "print 'Test:', len(test_sentences_words), len(test_sentences_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW + Cls Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_instances(words, tags, bow, count_vectorizer):\n",
    "    X = []\n",
    "    y = []\n",
    "    for w, t in zip(words, tags):\n",
    "        v = count_vectorizer.transform([w])[0]\n",
    "        v = scipy.sparse.hstack([v, bow])\n",
    "        X.append(v)\n",
    "        y.append(t)\n",
    "        \n",
    "    return scipy.sparse.vstack(X), y\n",
    "\n",
    "def sentences_to_instances(sentences_words, sentences_tags, count_vectorizer):\n",
    "    bows = count_vectorizer.transform(map(lambda s: ' '.join(s), sentences_words))\n",
    "    X = []\n",
    "    y = []\n",
    "    for words, tags, bow in zip(sentences_words, sentences_tags, bows):\n",
    "        sent_X, sent_y = sentence_to_instances(words, tags, bow, count_vectorizer)\n",
    "        X.append(sent_X)\n",
    "        y += sent_y\n",
    "        \n",
    "    return scipy.sparse.vstack(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer().fit(map(lambda s: ' '.join(s), train_sentences_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((839214, 50892), (839214,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = sentences_to_instances(train_sentences_words, train_sentences_tags, count_vectorizer)\n",
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((209353, 50892), (209353,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X, test_y = sentences_to_instances(test_sentences_words, test_sentences_tags, count_vectorizer)\n",
    "test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dima/.virtualenvs/hs/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier().fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.57      0.05      0.09        82\n",
      "      B-eve       0.68      0.28      0.40        46\n",
      "      B-geo       0.91      0.40      0.56      7553\n",
      "      B-gpe       0.96      0.84      0.90      3242\n",
      "      B-nat       0.52      0.27      0.36        48\n",
      "      B-org       0.93      0.31      0.46      4082\n",
      "      B-per       0.80      0.52      0.63      3321\n",
      "      B-tim       0.91      0.66      0.76      4107\n",
      "      I-art       0.09      0.02      0.04        43\n",
      "      I-eve       0.33      0.02      0.04        44\n",
      "      I-geo       0.82      0.55      0.66      1408\n",
      "      I-gpe       0.86      0.62      0.72        40\n",
      "      I-nat       0.20      0.08      0.12        12\n",
      "      I-org       0.88      0.24      0.38      3470\n",
      "      I-per       0.93      0.25      0.40      3332\n",
      "      I-tim       0.67      0.15      0.25      1308\n",
      "          O       0.91      1.00      0.95    177215\n",
      "\n",
      "avg / total       0.91      0.91      0.89    209353\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(test_y, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28822, 17, 38366)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set(itertools.chain(*[[w for w in s] for s in train_sentences_words])) \n",
    "tags = set(itertools.chain(*[[w for w in s] for s in train_sentences_tags]))\n",
    "sentenecs_lens = map(len, train_sentences_words)\n",
    "len(vocab), len(tags), len(sentenecs_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.5510e+03, 1.5670e+04, 1.4854e+04, 3.8890e+03, 3.3800e+02,\n",
       "        5.2000e+01, 1.0000e+01, 1.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([  1. ,  11.3,  21.6,  31.9,  42.2,  52.5,  62.8,  73.1,  83.4,\n",
       "         93.7, 104. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11deaf150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sentenecs_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 75#max(sentenecs_lens)\n",
    "VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dima/.virtualenvs/hs/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens: 28824\n"
     ]
    }
   ],
   "source": [
    "words_tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters=[], oov_token='__UNKNOWN__')\n",
    "words_tokenizer.fit_on_texts(map(lambda s: ' '.join(s), train_sentences_words))\n",
    "word_index = words_tokenizer.word_index\n",
    "word_index['__PADDING__'] = 0\n",
    "index_word = {i:w for w, i in word_index.iteritems()}\n",
    "print 'Unique tokens:', len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = words_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), train_sentences_words))\n",
    "test_sequences = words_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), test_sentences_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38366, 75) (9592, 75)\n"
     ]
    }
   ],
   "source": [
    "train_sequences_padded = pad_sequences(train_sequences, maxlen=MAX_LEN)\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=MAX_LEN)\n",
    "\n",
    "print train_sequences_padded.shape, test_sequences_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tags: 19\n"
     ]
    }
   ],
   "source": [
    "tags_tokenizer = Tokenizer(num_words=len(tags), filters='', oov_token='__UNKNOWN__', lower=False)\n",
    "tags_tokenizer.fit_on_texts(map(lambda s: ' '.join(s), train_sentences_tags))\n",
    "tag_index = tags_tokenizer.word_index\n",
    "tag_index['__PADDING__'] = 0\n",
    "index_tag = {i:w for w, i in tag_index.iteritems()}\n",
    "\n",
    "index_tag_wo_padding = dict(index_tag)\n",
    "index_tag_wo_padding[tag_index['__PADDING__']] = '0'\n",
    "print 'Unique tags:', len(tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tags = tags_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), train_sentences_tags))\n",
    "test_tags = tags_tokenizer.texts_to_sequences(map(lambda s: ' '.join(s), test_sentences_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38366, 75, 1) (9592, 75, 1)\n"
     ]
    }
   ],
   "source": [
    "train_tags_padded = pad_sequences(train_tags, maxlen=MAX_LEN)\n",
    "test_tags_padded = pad_sequences(test_tags, maxlen=MAX_LEN)\n",
    "\n",
    "train_tags_padded = np.expand_dims(train_tags_padded, -1)\n",
    "test_tags_padded = np.expand_dims(test_tags_padded, -1)\n",
    "print train_tags_padded.shape, test_tags_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "__PADDING__ __PADDING__\n",
      "not O\n",
      "counting O\n",
      "the O\n",
      "latest O\n",
      "death O\n",
      ", O\n",
      "the O\n",
      "world B-org\n",
      "health I-org\n",
      "organization I-org\n",
      "says O\n",
      "227 O\n",
      "people O\n",
      "around O\n",
      "the O\n",
      "world O\n",
      "have O\n",
      "died O\n",
      "from O\n",
      "bird O\n",
      "flu O\n",
      "since O\n",
      "2003 B-tim\n",
      ". O\n"
     ]
    }
   ],
   "source": [
    "for w, t in zip(train_sequences_padded[123], train_tags_padded[123]):\n",
    "    print index_word[w], index_tag[t[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, LSTM, Embedding, Bidirectional, Dropout\n",
    "from keras.models import Model\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 75, 300)           8646600   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 75, 128)           186880    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 75, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 75, 19)            627       \n",
      "=================================================================\n",
      "Total params: 8,838,235\n",
      "Trainable params: 8,838,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "random_embedding_layer = Embedding(VOCAB_SIZE,\n",
    "                                300,\n",
    "                                input_length=MAX_LEN)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype='int32')\n",
    "embedded_sequences = random_embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "preds = Dense(len(tag_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38366 samples, validate on 9592 samples\n",
      "Epoch 1/10\n",
      "38366/38366 [==============================] - 274s 7ms/step - loss: 0.1307 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.0465 - val_sparse_categorical_accuracy: 0.9869\n",
      "Epoch 2/10\n",
      "38366/38366 [==============================] - 276s 7ms/step - loss: 0.0365 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0438 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 3/10\n",
      "38366/38366 [==============================] - 264s 7ms/step - loss: 0.0280 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0470 - val_sparse_categorical_accuracy: 0.9880\n",
      "Epoch 4/10\n",
      "38366/38366 [==============================] - 261s 7ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9928 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9878\n",
      "Epoch 5/10\n",
      "38366/38366 [==============================] - 263s 7ms/step - loss: 0.0189 - sparse_categorical_accuracy: 0.9939 - val_loss: 0.0531 - val_sparse_categorical_accuracy: 0.9878\n",
      "Epoch 6/10\n",
      "38366/38366 [==============================] - 294s 8ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0625 - val_sparse_categorical_accuracy: 0.9874\n",
      "Epoch 7/10\n",
      "38366/38366 [==============================] - 318s 8ms/step - loss: 0.0129 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0668 - val_sparse_categorical_accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "38366/38366 [==============================] - 275s 7ms/step - loss: 0.0107 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.0685 - val_sparse_categorical_accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "38366/38366 [==============================] - 270s 7ms/step - loss: 0.0089 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0757 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 10/10\n",
      "38366/38366 [==============================] - 266s 7ms/step - loss: 0.0076 - sparse_categorical_accuracy: 0.9975 - val_loss: 0.0801 - val_sparse_categorical_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124b9f750>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sequences_padded, train_tags_padded,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(test_sequences_padded, test_tags_padded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = model.predict(test_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "bow_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words, lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = map(index_tag_wo_padding.get,tags)[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)\n",
    "    \n",
    "    bow_vector, _ = sentences_to_instances([s], [['x']*len(s)], count_vectorizer)\n",
    "    bow_predicted = clf.predict(bow_vector)[0]\n",
    "    bow_predicted_tags.append(bow_predicted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        art       0.11      0.10      0.10        82\n",
      "        gpe       0.94      0.96      0.95      3242\n",
      "        eve       0.21      0.33      0.26        46\n",
      "        per       0.66      0.58      0.62      3321\n",
      "        tim       0.84      0.83      0.84      4107\n",
      "        nat       0.00      0.00      0.00        48\n",
      "        org       0.58      0.55      0.57      4082\n",
      "        geo       0.83      0.83      0.83      7553\n",
      "\n",
      "avg / total       0.77      0.75      0.76     22481\n",
      "\n",
      "\n",
      "BOW\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        art       0.00      0.00      0.00        82\n",
      "        gpe       0.01      0.00      0.00      3242\n",
      "        eve       0.00      0.00      0.00        46\n",
      "        per       0.00      0.00      0.00      3321\n",
      "        tim       0.00      0.00      0.00      4107\n",
      "        nat       0.00      0.00      0.00        48\n",
      "        org       0.01      0.00      0.00      4082\n",
      "        geo       0.03      0.00      0.00      7553\n",
      "\n",
      "avg / total       0.01      0.00      0.00     22481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'LSTM'\n",
    "print '='*15\n",
    "print classification_report(test_sentences_tags, lstm_predicted_tags)\n",
    "print \n",
    "print 'BOW'\n",
    "print '='*15\n",
    "print classification_report(test_sentences_tags, bow_predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM: 0.764890423635\n",
      "BOW: 0.00173632642937\n"
     ]
    }
   ],
   "source": [
    "print 'LSTM:', f1_score(test_sentences_tags, lstm_predicted_tags)\n",
    "print 'BOW:', f1_score(test_sentences_tags, bow_predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Trained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = '/Users/dima/Downloads/glove.6B/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# vectors: 400000\n"
     ]
    }
   ],
   "source": [
    "embeddings = {}\n",
    "with open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings[word] = coefs\n",
    "\n",
    "print '# vectors:',  len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare embedding matrix\n",
    "num_words = min(VOCAB_SIZE, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, 300))\n",
    "for word, i in word_index.items():\n",
    "    if i >= VOCAB_SIZE:\n",
    "        continue\n",
    "    embedding_vector = embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 75, 300)           8646600   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 75, 128)           186880    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 75, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 75, 19)            627       \n",
      "=================================================================\n",
      "Total params: 8,838,235\n",
      "Trainable params: 191,635\n",
      "Non-trainable params: 8,646,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_embedding_layer = Embedding(VOCAB_SIZE,\n",
    "                                300,\n",
    "                                embeddings_initializer=Constant(embedding_matrix),\n",
    "                                input_length=MAX_LEN,\n",
    "                                trainable=False)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype='int32')\n",
    "embedded_sequences = pretrained_embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "preds = Dense(len(tag_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38366 samples, validate on 9592 samples\n",
      "Epoch 1/10\n",
      "38366/38366 [==============================] - 143s 4ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9676 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9853\n",
      "Epoch 2/10\n",
      "38366/38366 [==============================] - 143s 4ms/step - loss: 0.0488 - sparse_categorical_accuracy: 0.9859 - val_loss: 0.0429 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 3/10\n",
      "38366/38366 [==============================] - 138s 4ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.0401 - val_sparse_categorical_accuracy: 0.9881\n",
      "Epoch 4/10\n",
      "38366/38366 [==============================] - 132s 3ms/step - loss: 0.0381 - sparse_categorical_accuracy: 0.9885 - val_loss: 0.0391 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 5/10\n",
      "38366/38366 [==============================] - 146s 4ms/step - loss: 0.0355 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 6/10\n",
      "38366/38366 [==============================] - 143s 4ms/step - loss: 0.0333 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.0373 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "38366/38366 [==============================] - 145s 4ms/step - loss: 0.0318 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0355 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 8/10\n",
      "38366/38366 [==============================] - 142s 4ms/step - loss: 0.0303 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0352 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 9/10\n",
      "38366/38366 [==============================] - 138s 4ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0362 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "38366/38366 [==============================] - 137s 4ms/step - loss: 0.0278 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11b4b5950>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sequences_padded, train_tags_padded,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_data=(test_sequences_padded, test_tags_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = model.predict(test_sequences_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words, lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = map(index_tag_wo_padding.get,tags)[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM + Pretrained Embbeddings\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        art       0.45      0.06      0.11        82\n",
      "        gpe       0.97      0.95      0.96      3242\n",
      "        eve       0.56      0.33      0.41        46\n",
      "        per       0.72      0.71      0.72      3321\n",
      "        tim       0.87      0.84      0.85      4107\n",
      "        nat       0.00      0.00      0.00        48\n",
      "        org       0.62      0.56      0.59      4082\n",
      "        geo       0.83      0.88      0.86      7553\n",
      "\n",
      "avg / total       0.80      0.80      0.80     22481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'LSTM + Pretrained Embbeddings'\n",
    "print '='*15\n",
    "print classification_report(test_sentences_tags, lstm_predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM+Glove: 0.796080614631\n"
     ]
    }
   ],
   "source": [
    "print 'LSTM+Glove:', f1_score(test_sentences_tags, lstm_predicted_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/8z/y0djn01s3czbzxwmzmpsmvfh0000gn/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
     ]
    }
   ],
   "source": [
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.tables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\n",
    "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
    "                            \"sequence_len\": tf.constant(32*[MAX_LEN])\n",
    "                      },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 75, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 75, 128)           557568    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 75, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 75, 32)            4128      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 75, 19)            627       \n",
      "=================================================================\n",
      "Total params: 562,323\n",
      "Trainable params: 562,323\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "elmo_embedding_layer = Lambda(ElmoEmbedding, output_shape=(MAX_LEN, 1024))\n",
    "\n",
    "sequence_input = Input(shape=(MAX_LEN,), dtype=tf.string)\n",
    "embedded_sequences = elmo_embedding_layer(sequence_input)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(embedded_sequences)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "preds = Dense(len(tag_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_words_padded = [[index_word[w] for w in s] for s in train_sequences_padded]\n",
    "new_test_words_padded = [[index_word[w] for w in s] for s in test_sequences_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38336, 75), (38336, 75, 1), (9568, 75), (9568, 75, 1))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_words_padded = np.array(new_train_words_padded[:1198*32])\n",
    "new_train_tags_padded = train_tags_padded[:1198*32]\n",
    "\n",
    "new_test_words_padded = np.array(new_test_words_padded[:299*32])\n",
    "new_test_tags_padded = test_tags_padded[:299*32]\n",
    "\n",
    "\n",
    "new_train_words_padded.shape, new_train_tags_padded.shape, new_test_words_padded.shape, new_test_tags_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38336 samples, validate on 9568 samples\n",
      "Epoch 1/4\n",
      "38336/38336 [==============================] - 11761s 307ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0454 - val_sparse_categorical_accuracy: 0.9867\n",
      "Epoch 2/4\n",
      "38336/38336 [==============================] - 10230s 267ms/step - loss: 0.0279 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0506 - val_sparse_categorical_accuracy: 0.9866\n",
      "Epoch 3/4\n",
      "38336/38336 [==============================] - 10035s 262ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0540 - val_sparse_categorical_accuracy: 0.9863\n",
      "Epoch 4/4\n",
      "38336/38336 [==============================] - 10920s 285ms/step - loss: 0.0229 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.0584 - val_sparse_categorical_accuracy: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18a10a090>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_train_words_padded, new_train_tags_padded,\n",
    "          batch_size=32,\n",
    "          epochs=4,\n",
    "          validation_data=(new_test_words_padded, new_test_tags_padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted = model.predict(new_test_words_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_predicted_tags = []\n",
    "for s, s_pred in zip(test_sentences_words[:299*32], lstm_predicted):\n",
    "    tags = np.argmax(s_pred, axis=1)\n",
    "    tags = map(index_tag_wo_padding.get,tags)[-len(s):]\n",
    "    lstm_predicted_tags.append(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo\n",
      "===============\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        art       0.00      0.00      0.00        82\n",
      "        gpe       0.93      0.93      0.93      3242\n",
      "        eve       0.42      0.28      0.34        46\n",
      "        per       0.67      0.67      0.67      3321\n",
      "        tim       0.87      0.81      0.84      4107\n",
      "        nat       0.00      0.00      0.00        48\n",
      "        org       0.56      0.53      0.54      4082\n",
      "        geo       0.80      0.87      0.83      7553\n",
      "\n",
      "avg / total       0.76      0.77      0.77     22481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print 'ELMo'\n",
    "print '='*15\n",
    "print classification_report(test_sentences_tags, lstm_predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELMo: 0.737064459001\n"
     ]
    }
   ],
   "source": [
    "print 'ELMo:', f1_score(test_sentences_tags[:299*32], lstm_predicted_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hiredscore)",
   "language": "python",
   "name": "hiredscore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
